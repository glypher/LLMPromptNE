data_dir: /var/lib/vector

# Define the source to read logs from Docker container stdout
sources:
  conf_llm_logs:
    type: docker_logs
    include_containers:
      - conf_llm  # Replace with your container name
    auto_partial_merge: true

      #  vector_logs:
      #    type: internal_logs

# Define the sink to send logs to Elasticsearch
sinks:
  elasticsearch:
    type: elasticsearch
    inputs:
      - parse_python_logger
    endpoint: "http://elasticsearch:9200"  # Replace with your Elasticsearch endpoint
    # Optional: add authentication if required
    # auth:
    #   strategy: "basic"
    #   user: "<username>"
    #   password: "<password>"

      
#  console:
#    type: console
#    inputs:
#      - vector_logs
#    encoding:
#      codec: text

transforms:
  parse_python_logger:
    type: remap
    inputs:
      - conf_llm_logs
    source: |
      # Parse the log message using regex
      # 2024/06/30 15:04:32 - INFO - 0.0 - 0.88235 - Something to test
      . = parse_regex!(.message, r'^(?P<timestamp>\d+/\d+/\d+ \d+:\d+:\d+) - (?P<level>\S+) - (?P<infertime>\d+.\d+) - (?P<rougemetric>\d+.\d+) - (?P<log_message>.*)$')

      # Optionally, convert timestamp to a more usable format
      .timestamp = parse_timestamp(.timestamp, "%Y/%m/%d %H:%M:%S") ?? now()
      .infertime = to_float!(.infertime)
      .rougemetric = to_float!(.rougemetric)
