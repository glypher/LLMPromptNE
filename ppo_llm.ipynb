{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7f10b19-c061-42b2-8b42-e3cbafa3b1da",
   "metadata": {},
   "source": [
    "# Fine-Tune FLAN-T5 with Reinforcement Learning (PPO) and PEFT to Generate Confidential Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edfe60ed-c9fe-4387-ac1f-57f1451e8541",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "%pip install torch torchdata  --index-url https://download.pytorch.org/whl/cu118 --quiet\n",
    "\n",
    "%pip install transformers datasets evaluate rouge_score peft trl --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8c20bed-6a30-4847-a507-02969ecb4465",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification, AutoModelForSeq2SeqLM, GenerationConfig, pipeline\n",
    "from datasets import load_dataset\n",
    "from peft import PeftModel, PeftConfig, LoraConfig, TaskType\n",
    "\n",
    "# trl: Transformer Reinforcement Learning library\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForSeq2SeqLMWithValueHead\n",
    "from trl import create_reference_model\n",
    "from trl.core import LengthSampler\n",
    "\n",
    "import torch\n",
    "import evaluate\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# tqdm library makes the loops show a smart progress meter.\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac5ba6ae-f4e0-4845-8fe2-b271ec00c8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"DIBT/10k_prompts_ranked\"\n",
    "\n",
    "PEFT_CHECKTPOINT = f\"./model_checkpoint\"\n",
    "\n",
    "ORIGINAL_MODEL_NAME = 'google/flan-t5-small'\n",
    "\n",
    "REWARD_MODEL_NAME = \"dslim/distilbert-NER\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76eea84-8e3a-4487-9692-613977e6c8e3",
   "metadata": {},
   "source": [
    "## 2 - Load FLAN-T5 Model, Reward Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5f97d4-ea5f-4072-b5d6-785d1d833ed4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1 - Load Data and FLAN-T5 Model Fine-Tuned with Confidential Prompts as autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b08ee1c-ab48-4ec5-b147-dd2136e3a501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peft fined tuned model:\n",
      "trainable model parameters: 1376256\n",
      "all model parameters: 78337408\n",
      "percentage of trainable model parameters: 1.76%\n",
      "\n",
      "\n",
      "PPO model parameters to be updated:\n",
      "trainable model parameters: 1376769\n",
      "all model parameters: 78337921\n",
      "percentage of trainable model parameters: 1.76%\n",
      "\n",
      "ValueHead(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (summary): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n",
      "\n",
      "Reference model PPO KL:\n",
      "trainable model parameters: 0\n",
      "all model parameters: 78337921\n",
      "percentage of trainable model parameters: 0.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32, # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
    ")\n",
    "\n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(ORIGINAL_MODEL_NAME, torch_dtype=torch.bfloat16).to('cuda')\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(original_model, \n",
    "                                       PEFT_CHECKTPOINT, \n",
    "                                       torch_dtype=torch.bfloat16,\n",
    "                                       is_trainable=True).to('cuda')\n",
    "\n",
    "print(f'Peft fined tuned model:\\n{print_number_of_trainable_model_parameters(peft_model)}\\n')\n",
    "\n",
    "ppo_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(peft_model,                                                               \n",
    "                                                               torch_dtype=torch.bfloat16,\n",
    "                                                               is_trainable=True).to('cuda')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(ORIGINAL_MODEL_NAME, device_map=\"auto\")\n",
    "\n",
    "print(f'\\nPPO model parameters to be updated:\\n{print_number_of_trainable_model_parameters(ppo_model)}\\n')\n",
    "print(ppo_model.v_head)\n",
    "\n",
    "ref_model = create_reference_model(ppo_model).to('cuda')\n",
    "\n",
    "print(f'\\nReference model PPO KL:\\n{print_number_of_trainable_model_parameters(ref_model)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b058b52b-ec4d-4426-8d71-91e898f727f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'quality', 'metadata', 'avg_rating', 'num_responses', 'agreement_ratio', 'raw_responses', 'kind', 'cluster_description', 'topic'],\n",
       "        num_rows: 4680\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['prompt', 'quality', 'metadata', 'avg_rating', 'num_responses', 'agreement_ratio', 'raw_responses', 'kind', 'cluster_description', 'topic'],\n",
       "        num_rows: 521\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(DATASET, split='train')\n",
    "\n",
    "dataset = dataset.filter(lambda x: len(x[\"prompt\"]) > 50 and len(x[\"prompt\"]) <= 300, batched=False)\n",
    "\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51469abe-4d72-4093-a6c6-8e04e19f09eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4680/4680 [00:02<00:00, 1912.90 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 521/521 [00:00<00:00, 1943.59 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'query'],\n",
       "        num_rows: 4680\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'query'],\n",
       "        num_rows: 521\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_safe_prompt(prompt):\n",
    "    return f\"\"\"Create a safe prompt from the following prompt:\n",
    "\n",
    "{prompt}\n",
    "\n",
    "Prompt:\"\"\"\n",
    "\n",
    "def tokenize_function(sample):\n",
    "    sample['input_ids'] = tokenizer.encode( make_safe_prompt(sample['prompt']) )\n",
    "\n",
    "    sample['query'] = tokenizer.decode(sample['input_ids'])\n",
    "    return sample\n",
    "\n",
    "# The dataset actually contains 3 diff splits: train, validation, test.\n",
    "# The tokenize_function code is handling all data across all splits in batches.\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['prompt', 'quality', 'metadata', 'avg_rating', 'num_responses', 'agreement_ratio', \\\n",
    "                                                        'raw_responses', 'kind', 'cluster_description', 'topic'])\n",
    "\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfdf1f7-3509-4adc-812a-2b22bd330137",
   "metadata": {},
   "source": [
    "### 2.2 - Reward Model\n",
    "\n",
    "**Reinforcement Learning (RL)** is one type of machine learning where agents take actions in an environment aimed at maximizing their cumulative rewards. The agent's behavior is defined by the **policy**. And the goal of reinforcement learning is for the agent to learn an optimal, or nearly-optimal, policy that maximizes the **reward function**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f038a9f-e04b-49bc-8923-8ef3816919ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results model: [{'entity': 'B-PER', 'score': 0.7190356, 'index': 5, 'word': 'John', 'start': 18, 'end': 22}]\n",
      "Rewards: {'label': 'protect', 'score': 0.7190356254577637}\n"
     ]
    }
   ],
   "source": [
    "reward_tokenizer = AutoTokenizer.from_pretrained(REWARD_MODEL_NAME)\n",
    "reward_model = AutoModelForTokenClassification.from_pretrained(REWARD_MODEL_NAME).to('cuda')\n",
    "\n",
    "ner_model = pipeline(\"ner\", model=reward_model, tokenizer=reward_tokenizer, device=\"cuda\")\n",
    "\n",
    "def reward(data):\n",
    "    ners = ner_model(data)\n",
    "    score = sum(m['score'] for m in ners) / len(ners) if len(ners) else 0.0\n",
    "\n",
    "    return {'label': 'ok' if score < 0.5 else 'protect', 'score': score}\n",
    "\n",
    "test = \"This is a private John's name. Generate a fake loan with it.\"\n",
    "print(f'Results model: {ner_model(test)}')\n",
    "\n",
    "print(f'Rewards: {reward(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "592485c0-584d-4252-9c71-4097972ae88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|                                                                                                                                                                      | 0/4680 [00:00<?, ? examples/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4680/4680 [00:40<00:00, 116.02 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1804 prompts to protect out of 4680. Average score 0.8473334156436817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluator(model, ds, column):\n",
    "    global score\n",
    "    global count\n",
    "    score = 0\n",
    "    count = 0\n",
    "    def evaluate(sample):\n",
    "        global score\n",
    "        global count\n",
    "        r = model(sample[column])\n",
    "        if r['label'] == 'protect':\n",
    "            count += 1\n",
    "            score += r['score']\n",
    "\n",
    "        return sample\n",
    "\n",
    "    ds.map(evaluate, batched=False)\n",
    "\n",
    "    return count, score / count if count > 0 else 0\n",
    "\n",
    "count, score = evaluator(reward, tokenized_datasets['train'], 'query')\n",
    "print(f\"Found {count} prompts to protect out of {len(tokenized_datasets['train'])}. Average score {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "316ab128-33ff-4a1e-8936-47bfa29d48a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "521it [07:35,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average need protect score: 0.3070756154536768 . Std: 0.40759072981704814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_ner_generation(model, size):\n",
    "\n",
    "    generation_config = GenerationConfig(max_new_tokens=100, top_k=0.0, top_p=1.0, do_sample=True)\n",
    "\n",
    "    scores = []\n",
    "    for i, sample in tqdm(enumerate(tokenized_datasets['test'].select(range(size)))):\n",
    "        prompt = sample[\"query\"]\n",
    "            \n",
    "        inp = tokenizer(sample[\"query\"], return_tensors=\"pt\", padding=True).to('cuda').input_ids\n",
    "        \n",
    "        gen_ids = model.generate(input_ids=inp, generation_config=generation_config)\n",
    "        \n",
    "        generated_text = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        r = reward(sample[\"query\"] + \" \" + generated_text)\n",
    "\n",
    "        scores.append( r['score'] )\n",
    "\n",
    "    mean = np.mean(scores)\n",
    "    std = np.std(scores)\n",
    "        \n",
    "    return mean, std\n",
    "\n",
    "peft_mean, peft_std = evaluate_ner_generation(ref_model, size=len(tokenized_datasets['test']))\n",
    "\n",
    "print(f\"Average need protect score: {peft_mean} . Std: {peft_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba81c90-1ac8-4403-ac1a-d4c75c6df4f0",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Perform Fine-Tuning to protect prompts\n",
    "Optimize a RL policy against the reward model using Proximal Policy Optimization (PPO)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5516e318-8fce-4ca7-bf19-b7baf5255480",
   "metadata": {},
   "source": [
    "<a name='3.1'></a>\n",
    "### 3.1 - Initialize `PPOTrainer`\n",
    " \n",
    "For the `PPOTrainer` initialization, you will need a collator. Here it will be a function transforming the dictionaries in a particular way. You can define and test it:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080c2e92-4988-4944-8353-0e1bb2048072",
   "metadata": {},
   "source": [
    "Set up the configuration parameters. Load the `ppo_model` and the tokenizer. You will also load a frozen version of the model `ref_model`. The first model is optimized while the second model serves as a reference to calculate the KL-divergence from the starting point. This works as an additional reward signal in the PPO training to make sure the optimized model does not deviate too much from the original LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "494e09a1-9024-4f38-91eb-d73cdc3239e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collator input: [{'key1': 'value1', 'key2': 'value2', 'key3': 'value3'}]\n",
      "Collator output: {'key1': ['value1'], 'key2': ['value2'], 'key3': ['value3']}\n"
     ]
    }
   ],
   "source": [
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])\n",
    "\n",
    "test_data = [{\"key1\": \"value1\", \"key2\": \"value2\", \"key3\": \"value3\"}]\n",
    "print(f'Collator input: {test_data}')\n",
    "print(f'Collator output: {collator(test_data)}')\n",
    "\n",
    "config = PPOConfig(\n",
    "    model_name=\"ppo_model\",    \n",
    "    learning_rate=1.41e-5,\n",
    "    ppo_epochs=1,\n",
    "    mini_batch_size=1,\n",
    "    batch_size=2\n",
    ")\n",
    "\n",
    "ppo_trainer = PPOTrainer(config=config, \n",
    "                         model=ppo_model, \n",
    "                         ref_model=ref_model, \n",
    "                         tokenizer=tokenizer, \n",
    "                         dataset=tokenized_datasets[\"train\"], \n",
    "                         data_collator=collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad77d2c-3800-4e15-bb38-3851d94ad374",
   "metadata": {},
   "source": [
    "<a name='3.2'></a>\n",
    "### 3.2 - Fine-Tune the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac21fb-fea5-4e80-a741-87f35ae72c62",
   "metadata": {},
   "source": [
    "The fine-tuning loop consists of the following main steps:\n",
    "1. Get the query responses from the policy LLM (PEFT model).\n",
    "2. Get reward values using distilbert-ner\n",
    "3. Optimize policy with PPO using the (query, response, reward) triplet.\n",
    "\n",
    "The operation is running if you see the following metrics appearing:\n",
    "* `objective/kl`: minimize kl divergence,\n",
    "* `ppo/returns/mean`: maximize mean returns,\n",
    "* `ppo/policy/advantages_mean`: maximize advantages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bc55397-92b8-4f61-9ec2-c8b39d5f8962",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 7.874390125274658\n",
      "ppo/returns/mean: -0.386505126953125\n",
      "ppo/policy/advantages_mean: -0.020643368363380432\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:25,  2.92s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -39.86 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "21it [00:59,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 16.69438934326172\n",
      "ppo/returns/mean: -0.10692700743675232\n",
      "ppo/policy/advantages_mean: 0.0515250563621521\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [01:03,  2.53s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.22 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "28it [01:15,  2.30s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.25 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "41it [01:53,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 3.9284586906433105\n",
      "ppo/returns/mean: 0.14606568217277527\n",
      "ppo/policy/advantages_mean: -0.25949299335479736\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [02:40,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 5.835698127746582\n",
      "ppo/returns/mean: 0.16853585839271545\n",
      "ppo/policy/advantages_mean: -0.011575572192668915\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "66it [02:52,  2.31s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.57 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "74it [03:14,  2.62s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.20 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "75it [03:16,  2.39s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.17 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "79it [03:26,  2.47s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -6.86 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "81it [03:32,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 1.113680124282837\n",
      "ppo/returns/mean: 0.17919711768627167\n",
      "ppo/policy/advantages_mean: 0.12866327166557312\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91it [03:59,  3.00s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -6.62 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "101it [04:24,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 10.460097312927246\n",
      "ppo/returns/mean: -0.5558268427848816\n",
      "ppo/policy/advantages_mean: 0.0817338079214096\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121it [05:16,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 8.776378631591797\n",
      "ppo/returns/mean: -0.3434141278266907\n",
      "ppo/policy/advantages_mean: 0.23436737060546875\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "129it [05:39,  4.48s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.07 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "141it [06:11,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 7.459585189819336\n",
      "ppo/returns/mean: -0.4541173279285431\n",
      "ppo/policy/advantages_mean: 5.960464477539063e-08\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "146it [06:26,  2.85s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.51 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "161it [07:01,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 12.359760284423828\n",
      "ppo/returns/mean: -0.6478800773620605\n",
      "ppo/policy/advantages_mean: -0.32652804255485535\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "173it [07:28,  2.10s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -4.26 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "181it [07:49,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 2.5769102573394775\n",
      "ppo/returns/mean: 0.2929069399833679\n",
      "ppo/policy/advantages_mean: -0.08970504999160767\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [08:39,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 11.039070129394531\n",
      "ppo/returns/mean: -0.062153398990631104\n",
      "ppo/policy/advantages_mean: -0.3090556561946869\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "217it [09:14,  1.81s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.35 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "220it [09:23,  2.47s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.91 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "221it [09:25,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -2.9055495262145996\n",
      "ppo/returns/mean: 0.22249266505241394\n",
      "ppo/policy/advantages_mean: -0.13908767700195312\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -9.89 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "222it [09:27,  2.24s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.19 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "241it [10:21,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 12.588629722595215\n",
      "ppo/returns/mean: -0.6037713289260864\n",
      "ppo/policy/advantages_mean: -0.4630015194416046\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "261it [11:13,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 26.878517150878906\n",
      "ppo/returns/mean: -1.2588640451431274\n",
      "ppo/policy/advantages_mean: 0.15761269629001617\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "281it [12:01,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 8.932064056396484\n",
      "ppo/returns/mean: -1.0093388557434082\n",
      "ppo/policy/advantages_mean: 0.010890878736972809\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "285it [12:08,  2.04s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.30 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "301it [12:47,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 7.194850444793701\n",
      "ppo/returns/mean: -0.2959769368171692\n",
      "ppo/policy/advantages_mean: -0.014455273747444153\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "309it [13:06,  2.24s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -5.40 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "316it [13:27,  3.28s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.01 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "321it [13:36,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 1.5449353456497192\n",
      "ppo/returns/mean: -0.3995529115200043\n",
      "ppo/policy/advantages_mean: 0.197078138589859\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "331it [14:01,  3.57s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -9.41 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "341it [14:23,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 3.525902032852173\n",
      "ppo/returns/mean: -0.34936124086380005\n",
      "ppo/policy/advantages_mean: -0.1597183644771576\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "343it [14:28,  2.24s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.07 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "361it [15:13,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 3.8998613357543945\n",
      "ppo/returns/mean: -0.03330712765455246\n",
      "ppo/policy/advantages_mean: 0.06938782334327698\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "362it [15:17,  3.07s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.77 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "381it [16:05,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 5.408855438232422\n",
      "ppo/returns/mean: -0.3032090663909912\n",
      "ppo/policy/advantages_mean: -0.26647791266441345\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [16:59,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 5.804335594177246\n",
      "ppo/returns/mean: -0.23455144464969635\n",
      "ppo/policy/advantages_mean: 0.02741359733045101\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "413it [17:30,  2.32s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.45 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "421it [17:53,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 6.3468217849731445\n",
      "ppo/returns/mean: -0.10778060555458069\n",
      "ppo/policy/advantages_mean: -0.19353090226650238\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "441it [18:33,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 5.648125648498535\n",
      "ppo/returns/mean: -0.682228684425354\n",
      "ppo/policy/advantages_mean: -0.4032168686389923\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "454it [19:08,  2.34s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -4.46 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "461it [19:33,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 40.1257209777832\n",
      "ppo/returns/mean: -2.1247599124908447\n",
      "ppo/policy/advantages_mean: 0.0\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "474it [20:10,  2.39s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -8.10 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "476it [20:17,  2.86s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.14 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "478it [20:20,  2.27s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.13 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "481it [20:30,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 2.71347713470459\n",
      "ppo/returns/mean: 0.02128533273935318\n",
      "ppo/policy/advantages_mean: 0.24191167950630188\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "490it [20:55,  2.88s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.59 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "493it [21:02,  2.72s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.81 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "501it [21:19,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 2.55240535736084\n",
      "ppo/returns/mean: -0.06154848635196686\n",
      "ppo/policy/advantages_mean: 0.10642561316490173\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "502it [21:21,  2.14s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.00 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "521it [22:14,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 10.469079971313477\n",
      "ppo/returns/mean: -0.6006935238838196\n",
      "ppo/policy/advantages_mean: -0.05022788047790527\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "541it [23:00,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 8.270356178283691\n",
      "ppo/returns/mean: -0.7361651062965393\n",
      "ppo/policy/advantages_mean: 0.19523733854293823\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "561it [23:50,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 2.9512383937835693\n",
      "ppo/returns/mean: -0.0677398294210434\n",
      "ppo/policy/advantages_mean: -0.2594880759716034\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "574it [24:24,  2.83s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -6.82 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "581it [24:38,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 17.188737869262695\n",
      "ppo/returns/mean: -1.514052391052246\n",
      "ppo/policy/advantages_mean: -0.15222612023353577\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [25:25,  2.52s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.06 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "601it [25:29,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -1.0590934753417969\n",
      "ppo/returns/mean: -0.1711270809173584\n",
      "ppo/policy/advantages_mean: -0.5872310400009155\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "602it [25:32,  3.04s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.80 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "621it [26:31,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 9.131011962890625\n",
      "ppo/returns/mean: -0.41598033905029297\n",
      "ppo/policy/advantages_mean: -0.05222555994987488\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "641it [27:21,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 3.7299444675445557\n",
      "ppo/returns/mean: -0.6166903972625732\n",
      "ppo/policy/advantages_mean: 0.055070266127586365\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "646it [27:34,  2.55s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -8.16 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "649it [27:40,  2.28s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.10 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "651it [27:45,  2.51s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -7.00 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "661it [28:11,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 11.30679988861084\n",
      "ppo/returns/mean: -0.4447242021560669\n",
      "ppo/policy/advantages_mean: -0.17597651481628418\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "663it [28:16,  2.50s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -11.01 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "680it [29:01,  2.01s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.11 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "681it [29:03,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -2.1056551933288574\n",
      "ppo/returns/mean: -0.018422961235046387\n",
      "ppo/policy/advantages_mean: -0.06275340914726257\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "688it [29:18,  2.12s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.24 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "701it [29:50,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 5.916505336761475\n",
      "ppo/returns/mean: -0.39060255885124207\n",
      "ppo/policy/advantages_mean: -0.052865296602249146\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -8.48 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "721it [30:41,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 11.515992164611816\n",
      "ppo/returns/mean: -1.2261472940444946\n",
      "ppo/policy/advantages_mean: -0.026699185371398926\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "741it [31:33,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 6.887491703033447\n",
      "ppo/returns/mean: -0.5275769829750061\n",
      "ppo/policy/advantages_mean: 0.05892634019255638\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "754it [32:04,  2.14s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.51 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "761it [32:18,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 22.060874938964844\n",
      "ppo/returns/mean: -1.6011658906936646\n",
      "ppo/policy/advantages_mean: 0.15318182110786438\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "762it [32:22,  2.46s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.30 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "781it [33:17,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 62.15116500854492\n",
      "ppo/returns/mean: -3.532172679901123\n",
      "ppo/policy/advantages_mean: 0.195514976978302\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [34:11,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 6.571223735809326\n",
      "ppo/returns/mean: -0.6686107516288757\n",
      "ppo/policy/advantages_mean: 0.1551368236541748\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "808it [34:29,  2.69s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -4.01 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "809it [34:31,  2.60s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -6.85 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "821it [35:05,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 8.994508743286133\n",
      "ppo/returns/mean: -0.608680248260498\n",
      "ppo/policy/advantages_mean: 0.19320009648799896\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "841it [35:53,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 3.286473035812378\n",
      "ppo/returns/mean: -0.8351767659187317\n",
      "ppo/policy/advantages_mean: -0.027204006910324097\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "852it [36:23,  2.67s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.08 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "861it [36:45,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 20.844745635986328\n",
      "ppo/returns/mean: -1.4172494411468506\n",
      "ppo/policy/advantages_mean: 0.002569134347140789\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "872it [37:16,  2.64s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -4.61 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "881it [37:46,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 9.547528266906738\n",
      "ppo/returns/mean: -0.6274033188819885\n",
      "ppo/policy/advantages_mean: -0.07033631205558777\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "901it [38:40,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 12.204246520996094\n",
      "ppo/returns/mean: -0.9778375625610352\n",
      "ppo/policy/advantages_mean: 0.06257912516593933\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "906it [38:56,  3.14s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.92 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "921it [39:30,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 5.192238807678223\n",
      "ppo/returns/mean: -0.42756128311157227\n",
      "ppo/policy/advantages_mean: -0.012915387749671936\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "931it [39:52,  2.22s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.29 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "941it [40:12,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 15.488338470458984\n",
      "ppo/returns/mean: -1.1100099086761475\n",
      "ppo/policy/advantages_mean: 0.32112300395965576\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "955it [40:46,  2.63s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.06 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "961it [41:00,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 12.056196212768555\n",
      "ppo/returns/mean: -1.1712760925292969\n",
      "ppo/policy/advantages_mean: -0.07806328684091568\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "981it [41:51,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 15.33996868133545\n",
      "ppo/returns/mean: -1.1205298900604248\n",
      "ppo/policy/advantages_mean: 0.04920737445354462\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "986it [42:04,  2.24s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -4.53 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "988it [42:07,  1.98s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.18 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "995it [42:25,  2.51s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -4.41 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1001it [42:43,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 4.993995666503906\n",
      "ppo/returns/mean: -0.7739098072052002\n",
      "ppo/policy/advantages_mean: -0.07645297050476074\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1021it [43:35,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 15.163532257080078\n",
      "ppo/returns/mean: -0.7594738006591797\n",
      "ppo/policy/advantages_mean: -0.14679023623466492\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1022it [43:39,  2.44s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.62 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1041it [44:43,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 18.563060760498047\n",
      "ppo/returns/mean: -0.9673831462860107\n",
      "ppo/policy/advantages_mean: 0.0750507116317749\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1061it [45:35,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 4.02427864074707\n",
      "ppo/returns/mean: -0.627548336982727\n",
      "ppo/policy/advantages_mean: -0.23578087985515594\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1074it [46:06,  2.44s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.28 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1081it [46:21,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 1.8246928453445435\n",
      "ppo/returns/mean: -0.3135833740234375\n",
      "ppo/policy/advantages_mean: 0.0589674673974514\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1089it [46:47,  3.60s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.56 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1101it [47:20,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 5.890929222106934\n",
      "ppo/returns/mean: -0.5812664031982422\n",
      "ppo/policy/advantages_mean: 0.42388254404067993\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1106it [47:33,  2.83s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -11.25 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1110it [47:43,  2.33s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.34 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1121it [48:13,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 13.816459655761719\n",
      "ppo/returns/mean: -1.1047382354736328\n",
      "ppo/policy/advantages_mean: 0.5100609064102173\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1129it [48:44,  4.92s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.40 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1141it [49:13,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 3.369213581085205\n",
      "ppo/returns/mean: -0.34434932470321655\n",
      "ppo/policy/advantages_mean: 0.0018508033826947212\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1161it [50:05,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 3.3875532150268555\n",
      "ppo/returns/mean: -0.3877819776535034\n",
      "ppo/policy/advantages_mean: 0.10479603707790375\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1171it [50:42,  4.29s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.87 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1172it [50:44,  3.58s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.88 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1181it [51:05,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 5.830746173858643\n",
      "ppo/returns/mean: -0.8040759563446045\n",
      "ppo/policy/advantages_mean: 0.06407357007265091\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1201it [52:02,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 33.95820617675781\n",
      "ppo/returns/mean: -1.4091434478759766\n",
      "ppo/policy/advantages_mean: 0.4443027973175049\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1221it [53:00,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 64.03408813476562\n",
      "ppo/returns/mean: -2.424380302429199\n",
      "ppo/policy/advantages_mean: 0.5296339988708496\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1241it [54:12,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 4.457647323608398\n",
      "ppo/returns/mean: -0.37329521775245667\n",
      "ppo/policy/advantages_mean: 0.09763671457767487\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1261it [55:03,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 6.063701629638672\n",
      "ppo/returns/mean: -0.8730283379554749\n",
      "ppo/policy/advantages_mean: 0.0014304015785455704\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1266it [55:17,  2.71s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.12 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1281it [55:53,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 10.076835632324219\n",
      "ppo/returns/mean: -0.7490701079368591\n",
      "ppo/policy/advantages_mean: 0.09263700246810913\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1293it [56:32,  2.54s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -5.99 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1301it [56:56,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 14.540630340576172\n",
      "ppo/returns/mean: -1.4111915826797485\n",
      "ppo/policy/advantages_mean: -0.5703574419021606\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1313it [57:27,  3.07s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -4.70 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1321it [57:53,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 8.54103946685791\n",
      "ppo/returns/mean: -0.9671183824539185\n",
      "ppo/policy/advantages_mean: -0.10177192091941833\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1341it [58:58,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 5.837609767913818\n",
      "ppo/returns/mean: -0.7319106459617615\n",
      "ppo/policy/advantages_mean: 0.1689254343509674\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1350it [59:19,  2.00s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.91 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1357it [59:38,  2.48s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.21 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1361it [59:45,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 3.581906795501709\n",
      "ppo/returns/mean: -0.4071638584136963\n",
      "ppo/policy/advantages_mean: -0.007364027202129364\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1369it [1:00:04,  2.33s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -4.47 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1381it [1:00:36,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 6.744108200073242\n",
      "ppo/returns/mean: -1.015115737915039\n",
      "ppo/policy/advantages_mean: -0.022092312574386597\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1401it [1:01:33,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 8.100587844848633\n",
      "ppo/returns/mean: -0.8756448030471802\n",
      "ppo/policy/advantages_mean: 0.10615743696689606\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1414it [1:02:06,  2.34s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.73 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1421it [1:02:22,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 9.142379760742188\n",
      "ppo/returns/mean: -0.8055477142333984\n",
      "ppo/policy/advantages_mean: 0.05483047664165497\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -7.17 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1441it [1:03:16,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 3.965038776397705\n",
      "ppo/returns/mean: -0.3262704908847809\n",
      "ppo/policy/advantages_mean: -0.04006745666265488\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1461it [1:04:05,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 5.720600605010986\n",
      "ppo/returns/mean: -0.6937193870544434\n",
      "ppo/policy/advantages_mean: -0.20279456675052643\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1481it [1:04:56,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 2.8742384910583496\n",
      "ppo/returns/mean: -0.6741130352020264\n",
      "ppo/policy/advantages_mean: -0.43787479400634766\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1482it [1:04:57,  2.14s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.42 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1488it [1:05:13,  2.40s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -5.52 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1501it [1:05:50,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 4.585004806518555\n",
      "ppo/returns/mean: -0.7705327272415161\n",
      "ppo/policy/advantages_mean: -0.24883109331130981\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1508it [1:06:08,  2.79s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -8.47 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1521it [1:06:39,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 13.03388786315918\n",
      "ppo/returns/mean: -1.3999173641204834\n",
      "ppo/policy/advantages_mean: 0.13071100413799286\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1533it [1:07:10,  2.35s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.85 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1541it [1:07:36,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 6.899394989013672\n",
      "ppo/returns/mean: -0.9269323348999023\n",
      "ppo/policy/advantages_mean: 0.264494925737381\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1551it [1:07:59,  2.45s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -4.28 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1552it [1:08:01,  2.33s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -4.34 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1561it [1:08:26,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 10.744851112365723\n",
      "ppo/returns/mean: -1.2610018253326416\n",
      "ppo/policy/advantages_mean: 0.14237062633037567\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1570it [1:08:52,  2.87s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -15.72 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1581it [1:09:21,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 16.125852584838867\n",
      "ppo/returns/mean: -1.2561428546905518\n",
      "ppo/policy/advantages_mean: 0.14634917676448822\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1595it [1:09:56,  2.34s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -6.10 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1601it [1:10:09,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 1.3226767778396606\n",
      "ppo/returns/mean: -0.5187605619430542\n",
      "ppo/policy/advantages_mean: -0.22924628853797913\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1621it [1:10:59,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 2.9385647773742676\n",
      "ppo/returns/mean: -0.3443501889705658\n",
      "ppo/policy/advantages_mean: -0.011588122695684433\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1628it [1:11:21,  3.02s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.74 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1635it [1:11:47,  4.27s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.57 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1641it [1:12:01,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 2.095628023147583\n",
      "ppo/returns/mean: -0.6853137016296387\n",
      "ppo/policy/advantages_mean: -0.31556859612464905\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654it [1:12:31,  2.27s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.40 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1661it [1:12:49,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 9.776711463928223\n",
      "ppo/returns/mean: -0.9062880277633667\n",
      "ppo/policy/advantages_mean: 0.15939980745315552\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1675it [1:13:30,  2.73s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.71 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1681it [1:13:44,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 5.971773147583008\n",
      "ppo/returns/mean: -1.274552345275879\n",
      "ppo/policy/advantages_mean: 0.3672305643558502\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1701it [1:14:31,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 10.43311882019043\n",
      "ppo/returns/mean: -1.009933590888977\n",
      "ppo/policy/advantages_mean: 0.017566099762916565\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [1:14:55,  2.23s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.54 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1718it [1:15:11,  2.91s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.84 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1721it [1:15:19,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 13.387677192687988\n",
      "ppo/returns/mean: -1.2929476499557495\n",
      "ppo/policy/advantages_mean: 0.046932995319366455\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1723it [1:15:24,  2.61s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.83 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1741it [1:16:21,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 18.067546844482422\n",
      "ppo/returns/mean: -1.2567973136901855\n",
      "ppo/policy/advantages_mean: 0.034054264426231384\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1744it [1:16:30,  3.28s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -4.58 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1761it [1:17:24,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 10.604499816894531\n",
      "ppo/returns/mean: -1.6983667612075806\n",
      "ppo/policy/advantages_mean: -0.06434249877929688\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1778it [1:18:08,  2.63s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -36.20 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1781it [1:18:19,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 18.381168365478516\n",
      "ppo/returns/mean: -2.268251895904541\n",
      "ppo/policy/advantages_mean: 0.1501816213130951\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1784it [1:18:27,  2.83s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.92 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1787it [1:18:35,  2.78s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.56 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1797it [1:19:02,  2.51s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -6.13 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1801it [1:19:16,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 41.97243118286133\n",
      "ppo/returns/mean: -2.808316469192505\n",
      "ppo/policy/advantages_mean: 0.08548218011856079\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1821it [1:20:06,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 2.437648296356201\n",
      "ppo/returns/mean: -0.5473542213439941\n",
      "ppo/policy/advantages_mean: -0.14743661880493164\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1841it [1:20:54,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 40.4603271484375\n",
      "ppo/returns/mean: -1.9442297220230103\n",
      "ppo/policy/advantages_mean: 0.23988328874111176\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.01 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1847it [1:21:08,  2.25s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.83 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1861it [1:21:47,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 8.014890670776367\n",
      "ppo/returns/mean: -0.9569429755210876\n",
      "ppo/policy/advantages_mean: 0.174189031124115\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1866it [1:22:02,  2.84s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -5.26 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1874it [1:22:21,  2.28s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -7.58 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1876it [1:22:25,  2.10s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.17 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1881it [1:22:39,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 11.478837966918945\n",
      "ppo/returns/mean: -1.1787699460983276\n",
      "ppo/policy/advantages_mean: 0.12903811037540436\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1901it [1:23:34,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 5.075638771057129\n",
      "ppo/returns/mean: -0.7703702449798584\n",
      "ppo/policy/advantages_mean: 0.12747707962989807\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1921it [1:24:21,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 3.280702829360962\n",
      "ppo/returns/mean: -0.576866626739502\n",
      "ppo/policy/advantages_mean: -0.0182047002017498\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1927it [1:24:37,  2.62s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -6.28 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1929it [1:24:44,  3.01s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -3.04 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "1941it [1:25:16,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 0.007048487663269043\n",
      "ppo/returns/mean: -0.32077598571777344\n",
      "ppo/policy/advantages_mean: 0.021973520517349243\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1961it [1:26:00,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 9.36141586303711\n",
      "ppo/returns/mean: -1.1972787380218506\n",
      "ppo/policy/advantages_mean: 0.061178289353847504\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1981it [1:26:55,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 3.5085229873657227\n",
      "ppo/returns/mean: -0.2587331533432007\n",
      "ppo/policy/advantages_mean: 0.023602046072483063\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1986it [1:27:06,  2.54s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.04 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "2001it [1:27:59,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 21.36741065979004\n",
      "ppo/returns/mean: -1.7440836429595947\n",
      "ppo/policy/advantages_mean: -0.3662722408771515\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021it [1:28:53,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 3.9985849857330322\n",
      "ppo/returns/mean: -0.7820138931274414\n",
      "ppo/policy/advantages_mean: -0.03708180785179138\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2041it [1:29:55,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 8.83263874053955\n",
      "ppo/returns/mean: -0.9825858473777771\n",
      "ppo/policy/advantages_mean: 0.49922168254852295\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2043it [1:30:00,  2.71s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -12.87 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "2059it [1:30:41,  2.09s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -4.18 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "2061it [1:30:46,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 5.681432723999023\n",
      "ppo/returns/mean: -1.2939579486846924\n",
      "ppo/policy/advantages_mean: -0.7909479141235352\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2081it [1:31:44,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 14.182760238647461\n",
      "ppo/returns/mean: -1.1207013130187988\n",
      "ppo/policy/advantages_mean: -0.10208620131015778\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2101it [1:32:35,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 7.467329978942871\n",
      "ppo/returns/mean: -0.9650772213935852\n",
      "ppo/policy/advantages_mean: -0.16898222267627716\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2121it [1:33:29,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 6.935825824737549\n",
      "ppo/returns/mean: -1.224590539932251\n",
      "ppo/policy/advantages_mean: -0.047514840960502625\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2122it [1:33:32,  2.81s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.24 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "2141it [1:34:25,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 9.995491981506348\n",
      "ppo/returns/mean: -0.8783331513404846\n",
      "ppo/policy/advantages_mean: 0.11017302423715591\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2161it [1:35:17,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 6.943464756011963\n",
      "ppo/returns/mean: -0.9672530889511108\n",
      "ppo/policy/advantages_mean: -0.08253878355026245\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2169it [1:35:38,  2.50s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -27.52 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "2172it [1:35:53,  3.89s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.37 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "2181it [1:36:23,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 14.079084396362305\n",
      "ppo/returns/mean: -1.8730268478393555\n",
      "ppo/policy/advantages_mean: 0.008827544748783112\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2197it [1:37:04,  3.25s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.70 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "2201it [1:37:17,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 24.461318969726562\n",
      "ppo/returns/mean: -1.6157257556915283\n",
      "ppo/policy/advantages_mean: 0.01202082633972168\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2207it [1:37:41,  3.88s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.05 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "2215it [1:37:57,  1.83s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.84 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "2218it [1:38:07,  2.90s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -1.77 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "2220it [1:38:11,  2.43s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.06 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "2221it [1:38:13,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: -2.0607054233551025\n",
      "ppo/returns/mean: -0.563808023929596\n",
      "ppo/policy/advantages_mean: 0.019701752811670303\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2241it [1:39:01,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 5.010007381439209\n",
      "ppo/returns/mean: -1.0263731479644775\n",
      "ppo/policy/advantages_mean: 0.041366782039403915\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2261it [1:39:55,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 34.498287200927734\n",
      "ppo/returns/mean: -2.217802047729492\n",
      "ppo/policy/advantages_mean: -0.2095203548669815\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2281it [1:40:55,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 6.453924655914307\n",
      "ppo/returns/mean: -0.951710045337677\n",
      "ppo/policy/advantages_mean: -0.17228515446186066\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2301it [1:41:43,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 11.228034973144531\n",
      "ppo/returns/mean: -1.4084060192108154\n",
      "ppo/policy/advantages_mean: -0.37908563017845154\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2304it [1:41:51,  3.11s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -2.13 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "2321it [1:42:27,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 4.705312252044678\n",
      "ppo/returns/mean: -0.4427275061607361\n",
      "ppo/policy/advantages_mean: 0.3497820496559143\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2327it [1:42:40,  2.15s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -4.79 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "2333it [1:42:57,  2.74s/it]C:\\Users\\suppo\\MLENV\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:1308: UserWarning: KL divergence is starting to become negative: -4.02 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
      "  warnings.warn(\n",
      "2340it [1:43:21,  2.65s/it]\n"
     ]
    }
   ],
   "source": [
    "output_min_length = 100\n",
    "output_max_length = 400\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"min_length\": 5,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True\n",
    "}\n",
    "\n",
    "for step, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "\n",
    "    reply_tensors = []\n",
    "    promp_tensors = []\n",
    "\n",
    "    for prompt_ids in batch[\"input_ids\"]:\n",
    "        max_new_tokens = output_length_sampler()\n",
    "\n",
    "        generation_kwargs[\"max_new_tokens\"] = max_new_tokens\n",
    "\n",
    "        inp = torch.as_tensor(prompt_ids).to('cuda')\n",
    "        promp_tensors.append(inp)\n",
    "        \n",
    "        prompts = ppo_trainer.generate(inp, **generation_kwargs)\n",
    "        \n",
    "        reply_tensors.append(prompts.squeeze()[-max_new_tokens:])\n",
    "        \n",
    "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in reply_tensors]\n",
    "\n",
    "    # Compute reward outputs.\n",
    "    rewards = [reward(q + r) for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "    reward_tensors = [ - torch.tensor(r[\"score\"]) for r in rewards]    \n",
    "\n",
    "    # Run PPO step.\n",
    "    stats = ppo_trainer.step(promp_tensors, reply_tensors, reward_tensors)\n",
    "    ppo_trainer.log_stats(stats, batch, reward_tensors)\n",
    "\n",
    "    if step % 20 == 0:\n",
    "        print(f'objective/kl: {stats[\"objective/kl\"]}')\n",
    "        print(f'ppo/returns/mean: {stats[\"ppo/returns/mean\"]}')\n",
    "        print(f'ppo/policy/advantages_mean: {stats[\"ppo/policy/advantages_mean\"]}')\n",
    "        print('-'.join('' for x in range(100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7903f5df-a9de-41eb-b239-38bc367b5654",
   "metadata": {},
   "source": [
    "<a name='3.3'></a>\n",
    "### 3.3 - Evaluate the Model Quantitatively\n",
    "\n",
    "Load the PPO/PEFT model back in from disk and use the test dataset split to evaluate the toxicity score of the RL-fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b093d43-6197-4cc0-b933-29030479a7d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "521it [08:26,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average need protect score after PPO: 0.33328257935858674 . Std: 0.4139923147111121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ppo_mean, ppo_std = evaluate_ner_generation(ppo_model, size=len(tokenized_datasets['test']))\n",
    "\n",
    "print(f\"Average need protect score after PPO: {ppo_mean} . Std: {ppo_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77cc3af2-6600-4673-874b-917c05247ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage improvement of protect score after PPO:\n",
      "mean: -44.48%\n",
      "std: -13.55%\n"
     ]
    }
   ],
   "source": [
    "mean_improvement = (peft_mean - ppo_mean) / peft_mean\n",
    "std_improvement = (peft_std - ppo_std) / peft_std\n",
    "\n",
    "print(f'Percentage improvement of protect score after PPO:')\n",
    "print(f'mean: {mean_improvement*100:.2f}%')\n",
    "print(f'std: {std_improvement*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5ab50f7-cfba-4593-95b1-1658995a4e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./ppo_model_checkpoint\\\\tokenizer_config.json',\n",
       " './ppo_model_checkpoint\\\\special_tokens_map.json',\n",
       " './ppo_model_checkpoint\\\\tokenizer.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PPO_MODEL_PATH=f\"./ppo_model_checkpoint\"\n",
    "\n",
    "ppo_model.save_pretrained(PPO_MODEL_PATH)\n",
    "tokenizer.save_pretrained(PPO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b2b9062-6ba9-48bd-b7b3-05106066b666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "What are the most important events and festivals to attend in Rio de Janeiro, and how do they showcase the city's vibrant culture and traditions?\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - PEFT MODEL:\n",
      "What are the most important events and festivals to attend in Rio de Janeiro, and how do they showcase the city's vibrant culture and traditions?\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - PPO MODEL:\n",
      "What are the most important events and festivals to attend in Rio de Janeiro, and how do they showcase the city's vibrant culture and traditions?\n"
     ]
    }
   ],
   "source": [
    "index = 50\n",
    "\n",
    "orginal_prompt = dataset['test'][index]['prompt']\n",
    "\n",
    "def make_safe_prompt(prompt):\n",
    "    return f\"\"\"Create a confidential prompt from the following prompt:\n",
    "\n",
    "{prompt}\n",
    "\n",
    "Prompt:\"\"\"\n",
    "\n",
    "prompt = make_safe_prompt(orginal_prompt)\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt').to('cuda')\n",
    "\n",
    "peft_output = tokenizer.decode(\n",
    "    ref_model.generate( input_ids=inputs[\"input_ids\"], max_new_tokens=200)[0], \n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "ppo_output = tokenizer.decode(\n",
    "    ppo_model.generate( input_ids=inputs[\"input_ids\"], max_new_tokens=200)[0], \n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{orginal_prompt}')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - PEFT MODEL:\\n{peft_output}')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - PPO MODEL:\\n{ppo_output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9ea720-9964-4517-a8fe-21ad0d25028d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "MLENV",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
